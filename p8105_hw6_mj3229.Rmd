---
title: "Homework 6"
subtitle: "Mahitha Jangeti"
output: github_document
---

```{r setup}
library(tidyverse)
library(ggplot2)
library(knitr)
library(rvest)
library(modelr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 10,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1)
```

## Problem 1

```{r}
library(tidyverse)

homicides_df = read_csv("data/homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = str_c(city, ", ", state), 
    resolved = if_else(disposition == "Closed by arrest", 1, 0),
    victim_age = as.numeric(victim_age)
  ) %>% 
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black")
  )
```

**Baltimore, MD** 
```{r}
baltimore_glm = 
  homicides_df %>% 
  filter(city_state == "Baltimore, MD") %>% 
  glm(resolved ~ victim_age + victim_sex + victim_race,
      family = binomial(),
      data = .)

baltimore_glm %>% 
  broom::tidy() %>% 
  mutate(
    odds_ratio = exp(estimate),
    ci_upper_odds_ratio = exp(estimate + 1.96 * std.error),
    ci_lower_odds_ratio = exp(estimate - 1.96 * std.error)
  ) %>% 
  filter(term == "victim_sexMale") %>% 
  select(odds_ratio, ci_lower_odds_ratio, ci_upper_odds_ratio) %>%  
  knitr::kable(digits = 3)
```

**Linear models for all states**

```{r}
cities_glm = 
  homicides_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = map(data, ~ glm(
      resolved ~ victim_age + victim_sex + victim_race,
      family = binomial(),
      data = .x
    )),
    tidy_models = map(models, broom::tidy)
  ) %>% 
  unnest(cols = tidy_models) %>% 
  mutate(
    odds_ratio = exp(estimate),
    ci_upper_odds_ratio = exp(estimate + 1.96 * std.error),
    ci_lower_odds_ratio = exp(estimate - 1.96 * std.error)
  ) %>% 
  filter(term == "victim_sexMale") %>% 
  select(city_state, odds_ratio, ci_lower_odds_ratio, ci_upper_odds_ratio)

cities_glm %>% 
  knitr::kable(digits = 3)
```

**All Cities OR and CI Plot**
```{r}
cities_glm %>% 
  mutate(city_state = fct_reorder(city_state, odds_ratio)) %>% 
  ggplot(aes(x = city_state, y = odds_ratio)) +
  geom_point(size = 2) +
  geom_errorbar(
    aes(ymin = ci_lower_odds_ratio, ymax = ci_upper_odds_ratio),
    width = 0
  ) +
  coord_flip() +
  labs(
    title = "Adjusted OR and CI for Solving Homicides (Male vs Female) by City",
    x = "City",
    y = "Adjusted Odds Ratio (with 95% CI)"
  ) +
  theme_minimal(base_size = 12) 
```

## Problem 2

```{r}
library(p8105.datasets)
data("weather_df")

weather_df =
  weather_df %>%
  mutate(
    tmin = tmin / 10,
    tmax = tmax / 10,
    prcp = prcp / 10
  ) %>%
  drop_na(tmin, tmax, prcp) %>%
  arrange(date)
```

Bootstrapping
```{r}
boot_rsq = function(fit) {
  fit %>% 
    broom::glance() %>% 
    pull(r.squared)
}

boot_beta = function(fit) {
  coefs = broom::tidy(fit)
  beta1 = coefs %>%  
    filter(term == "tmin") %>%  
    pull(estimate)
  beta2 = coefs %>%  
    filter(term == "prcp") %>% 
    pull(estimate)
  beta1 / beta2
}
```

5000 samples and estimates of ð‘ŸÌ‚2 andð›½Ì‚ 1/ð›½Ì‚ 2
```{r}
bootstrap_results =
  weather_df %>% 
  bootstrap(5000) %>% 
  mutate(
    models = map(strap, \(x) lm(tmax ~ tmin + prcp, data = x)),
    r2 = map_dbl(models, boot_rsq),
    beta1_beta2 = map_dbl(models, boot_beta)
  ) %>% 
  select(r2, beta1_beta2)
```

Distribution of estimates for Beta 
```{r}
ggplot(bootstrap_results, aes(x = beta1_beta2)) +
  geom_histogram(bins = 30, fill = "black", alpha = 0.7, color = "white") +
  labs(
    title = "Bootstrap Distribution of Beta1/Beta2",
    x = expression(beta[1] / beta[2]),
    y = "Frequency"
  )
```

The distribution of beta1/beta2 ratio is left-skewed with a wider range. There is much more variation here than R^2. The beta2 value is typically smaller because we are looking at effect of precipitation on tmax. Dividing by smaller number leaves results in large negative values as final answer, illustrated by the center of the distribution. The distribution is highly variable and unstable compared to R^2. 

Distribution of estimates for R2
```{r}
ggplot(bootstrap_results, aes(x = r2)) +
  geom_histogram(bins = 30, fill = "black", color = "white") +
  labs(title = "Bootstrap Distribution of RÂ²",
       x = "RÂ²",
       y = "Frequency")
```

The distribution for R^2 is approximately symmetric and seems normal. It seems to centered around 0.942 and has a tight fit. This may indicate that overall model fit is highly stable across the bootstrap samples. 

Identify the 2.5% and 97.5% quantiles
```{r}
bootstrap_quantile =
bootstrap_results %>% 
  summarize(
    r2_low = quantile(r2, 0.025),
    r2_high = quantile(r2, 0.975),
    beta_low = quantile(beta1_beta2, 0.025),
    beta_high = quantile(beta1_beta2, 0.975)
  )

knitr::kable(bootstrap_quantile, digits = 3)
```

## Problem 3
```{r}
birthweight_df = read_csv("data/birthweight.csv") %>% 
  janitor::clean_names() %>%                                   
  mutate(
    babysex = as.factor(babysex),                               
    frace = as.factor(frace),                                  
    malform = as.factor(malform),                               
    mrace = as.factor(mrace)                                    
  )

sum(is.na(birthweight_df))                                  
```

Regression Model for Birthweight

```{r}
birth_model =
  birthweight_df %>% 
  lm(bwt ~ bhead + blength + gaweeks + babysex + smoken + wtgain, data = .)
```

**Residuals vs Fitted Values Plot**

```{r}
birthweight_df %>% 
  modelr::add_predictions(birth_model) %>% 
  modelr::add_residuals(birth_model) %>%  
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  labs(title = "Residuals vs. Fitted Values",
       x = "Fitted Values",
       y = "Residuals") 
```

**Compare your model to two others**

```{r}
birth_model_2 = 
  lm(bwt ~ blength + gaweeks,
     data = birthweight_df)

birth_model_3 = 
  lm(bwt ~ bhead * blength * babysex,
     data = birthweight_df) 

set.seed(123)

cv_df =
  crossv_mc(birthweight_df, n = 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) %>% 
  mutate(
    mod_mod = map(train, ~lm(bwt ~ bhead + blength + gaweeks + delwt + smoken + wtgain + malform + ppbmi + babysex + momage + parity, data = .x)),
    comp2_mod = map(train, ~lm(bwt ~ gaweeks + blength, data = .x)),
    comp3_mod = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = .x))
  ) %>% 
  mutate(
    rmse_mod_mod = map2_dbl(mod_mod, test, ~rmse(model = .x, data = .y)),
    rmse_comp2_mod = map2_dbl(comp2_mod, test, ~rmse(model = .x, data = .y)),
    rmse_comp3_mod = map2_dbl(comp3_mod, test, ~rmse(model = .x, data = .y))
  )

cv_df %>%  
  summarise(mod1_mean_error = mean(rmse_mod_mod),
            mod2_mean_error = mean(rmse_comp2_mod),
            mod3_mean_error = mean(rmse_comp3_mod)) %>% 
  knitr::kable(digits = 3)
```

Comparing the three models, model 1 shoes the lowest RMSE, indicating the most accurate prediction for birthweight. The second model which includes length at birth and gestational age as predictors had the highest RMSE. Becuase it is a simpler model, might be the least accurate and reliable for birthweight. Lastly, model 3 which included head circumference, length, sex, and all interactions between these, had RMSE between the two other models. Despite the interaction, it didn't improve accuracy. From this, overal model 1 has the best balance of accuracy compared to the more complex and simple model. 
